<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Lo-Fi Python - positive thinking</title><link href="https://lofipython.com/" rel="alternate"></link><link href="https://lofipython.com/feeds/positive-thinking.tag.atom.xml" rel="self"></link><id>https://lofipython.com/</id><updated>2020-10-11T15:37:00-05:00</updated><entry><title>Google Vision OCR, Image Text and a Markov Chain: a recipe for positivipy</title><link href="https://lofipython.com/generating-positive-thoughts-with-google-vision-ocr-and-markov-chains.html" rel="alternate"></link><published>2020-10-11T15:37:00-05:00</published><updated>2020-10-11T15:37:00-05:00</updated><author><name>pythonmarketer</name></author><id>tag:lofipython.com,2020-10-11:/generating-positive-thoughts-with-google-vision-ocr-and-markov-chains.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Recently an old idea came back to life. I've posted to a &lt;a class="reference external" href="https://www.facebook.com/positivedailythought"&gt;Facebook Page&lt;/a&gt; for several years as part of project I started on a whim. The goal of the page is to share anything positive and inspirational by famous thinkers, artists and creators I read, or simply something â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Recently an old idea came back to life. I've posted to a &lt;a class="reference external" href="https://www.facebook.com/positivedailythought"&gt;Facebook Page&lt;/a&gt; for several years as part of project I started on a whim. The goal of the page is to share anything positive and inspirational by famous thinkers, artists and creators I read, or simply something positive to meditate on. It was partially inspired by the discipline of &amp;quot;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Positive_psychology"&gt;Positive Psychology&lt;/a&gt;&amp;quot;. Basically, William James was a cool dude. &lt;a class="reference external" href="https://www.ted.com/talks/martin_seligman_the_new_era_of_positive_psychology/transcript?language=en"&gt;Martin Seligman&lt;/a&gt; is too. I believe that positive feelings create positive outcomes and we can &amp;quot;game&amp;quot; ourselves into this feedback loop with literature and other habits that support well-being like sleep and exercise.&lt;/p&gt;
&lt;p&gt;After building up years of posts, I pondered for years how to capture the dataset of quote images to generate new positive-minded prose. This post details one implementation and alternatives I considered to accomplish this goal. All of the data and code in this post is &lt;a class="reference external" href="https://github.com/erickbytes/positivipy"&gt;published on Github&lt;/a&gt;. Possibly will post my entire &lt;a class="reference external" href="http://positivipy.com"&gt;flask website&lt;/a&gt; there eventually! Here's how I made my latest project, &lt;a class="reference external" href="https://positivethoughts.pythonanywhere.com/"&gt;positivipy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Project Overview&lt;/strong&gt;&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Export all Facebook post images from my page&lt;/li&gt;
&lt;li&gt;Convert images to quote text with &lt;strong&gt;Optical character recognition&lt;/strong&gt; (OCR)&lt;/li&gt;
&lt;li&gt;Data cleaning (via pandas and manual correction)&lt;/li&gt;
&lt;li&gt;Train on past quotes and generate new quotes with a Markov chain&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="export-all-facebook-post-images-from-my-page-1"&gt;
&lt;span id="export-all-facebook-post-images-from-my-page"&gt;&lt;/span&gt;&lt;h2&gt;1. Export all Facebook post images from my page&lt;/h2&gt;
&lt;p&gt;Facebook made this easy. I exported all of my timeline photos by &lt;a class="reference external" href="https://www.facebook.com/help/466076673571942"&gt;following these instructions&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="converting-images-to-quote-text-with-ocr-1"&gt;
&lt;span id="converting-images-to-quote-text-with-ocr"&gt;&lt;/span&gt;&lt;h2&gt;2. Converting images to quote text with OCR&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Optical character recognition&lt;/strong&gt; or &lt;strong&gt;optical character reader&lt;/strong&gt; (&lt;strong&gt;OCR&lt;/strong&gt;) is the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Electronics"&gt;electronic&lt;/a&gt; or &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Machine"&gt;mechanical&lt;/a&gt; conversion of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Image"&gt;images&lt;/a&gt; of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene-photo&lt;/p&gt;
&lt;p&gt;Wikipedia - &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Optical_character_recognition"&gt;https://en.wikipedia.org/wiki/Optical_character_recognition&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once I had a folder of .jpg images, I used the &lt;a class="reference external" href="https://github.com/googleapis/python-vision"&gt;Google Vision API&lt;/a&gt;'s OCR to detect the text in the images. I also considered using the open source &lt;a class="reference external" href="https://github.com/Calamari-OCR/calamari"&gt;Calamari OCR library&lt;/a&gt;, but my research found that Google's Vision API may be more effective at detecting text.&lt;/p&gt;
&lt;p&gt;Since I had only 771 images, I was able to extract text on all of them and stay within Google's free plan (1,000 requests / month). I &lt;a class="reference external" href="https://cloud.google.com/vision/docs/quickstart"&gt;followed these installation instructions&lt;/a&gt; on my Ubuntu Linux computer. It worked well on most of the images. Here's the code I used to detect text in all my images and save it in a .csv file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;span class="normal"&gt; 1&lt;/span&gt;
&lt;span class="normal"&gt; 2&lt;/span&gt;
&lt;span class="normal"&gt; 3&lt;/span&gt;
&lt;span class="normal"&gt; 4&lt;/span&gt;
&lt;span class="normal"&gt; 5&lt;/span&gt;
&lt;span class="normal"&gt; 6&lt;/span&gt;
&lt;span class="normal"&gt; 7&lt;/span&gt;
&lt;span class="normal"&gt; 8&lt;/span&gt;
&lt;span class="normal"&gt; 9&lt;/span&gt;
&lt;span class="normal"&gt;10&lt;/span&gt;
&lt;span class="normal"&gt;11&lt;/span&gt;
&lt;span class="normal"&gt;12&lt;/span&gt;
&lt;span class="normal"&gt;13&lt;/span&gt;
&lt;span class="normal"&gt;14&lt;/span&gt;
&lt;span class="normal"&gt;15&lt;/span&gt;
&lt;span class="normal"&gt;16&lt;/span&gt;
&lt;span class="normal"&gt;17&lt;/span&gt;
&lt;span class="normal"&gt;18&lt;/span&gt;
&lt;span class="normal"&gt;19&lt;/span&gt;
&lt;span class="normal"&gt;20&lt;/span&gt;
&lt;span class="normal"&gt;21&lt;/span&gt;
&lt;span class="normal"&gt;22&lt;/span&gt;
&lt;span class="normal"&gt;23&lt;/span&gt;
&lt;span class="normal"&gt;24&lt;/span&gt;
&lt;span class="normal"&gt;25&lt;/span&gt;
&lt;span class="normal"&gt;26&lt;/span&gt;
&lt;span class="normal"&gt;27&lt;/span&gt;
&lt;span class="normal"&gt;28&lt;/span&gt;
&lt;span class="normal"&gt;29&lt;/span&gt;
&lt;span class="normal"&gt;30&lt;/span&gt;
&lt;span class="normal"&gt;31&lt;/span&gt;
&lt;span class="normal"&gt;32&lt;/span&gt;
&lt;span class="normal"&gt;33&lt;/span&gt;
&lt;span class="normal"&gt;34&lt;/span&gt;
&lt;span class="normal"&gt;35&lt;/span&gt;
&lt;span class="normal"&gt;36&lt;/span&gt;
&lt;span class="normal"&gt;37&lt;/span&gt;
&lt;span class="normal"&gt;38&lt;/span&gt;
&lt;span class="normal"&gt;39&lt;/span&gt;
&lt;span class="normal"&gt;40&lt;/span&gt;
&lt;span class="normal"&gt;41&lt;/span&gt;
&lt;span class="normal"&gt;42&lt;/span&gt;
&lt;span class="normal"&gt;43&lt;/span&gt;
&lt;span class="normal"&gt;44&lt;/span&gt;
&lt;span class="normal"&gt;45&lt;/span&gt;
&lt;span class="normal"&gt;46&lt;/span&gt;
&lt;span class="normal"&gt;47&lt;/span&gt;
&lt;span class="normal"&gt;48&lt;/span&gt;
&lt;span class="normal"&gt;49&lt;/span&gt;
&lt;span class="normal"&gt;50&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;google.cloud&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;vision&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;


&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Setup Instructions&lt;/span&gt;
&lt;span class="sd"&gt;1) Save this as detect_image_text.py&lt;/span&gt;
&lt;span class="sd"&gt;2) Create a folder named &amp;#39;photos&amp;#39; and put your photos in them.&lt;/span&gt;
&lt;span class="sd"&gt;3) in your terminal, run: python detect_image_text.py&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;detect_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Detects text in the file.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vision&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ImageAnnotatorClient&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;image_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vision&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_detection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;texts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_annotations&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Texts:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;For more info on error messages, check: &amp;quot;&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;https://cloud.google.com/apis/design/errors&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/images&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;img_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;img_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;photos/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;detect_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;img_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Failed: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;quotes_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Extracted Image Text.csv&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;quotes_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="data-cleaning-via-pandas-and-manual-correction-1"&gt;
&lt;span id="data-cleaning-via-pandas-and-manual-correction"&gt;&lt;/span&gt;&lt;h2&gt;3. Data cleaning (via &lt;a class="reference external" href="https://pythonmarketer.wordpress.com/2018/05/12/pandas-pythons-excel-powerhouse/"&gt;pandas&lt;/a&gt; and manual correction)&lt;/h2&gt;
&lt;p&gt;The data did not come back perfect, but I was pleased with the Google Vision API's results. It saved me a lot of time compared to manually transcribing the images! Next I used pandas to clean the data. You can see more in a Jupyter notebook with &lt;a class="reference external" href="https://github.com/erickbytes/positivipy"&gt;all of the code on github&lt;/a&gt;. Then I manually removed the author or source names, keeping only the quote text.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="train-on-past-quotes-and-generate-new-quotes-1"&gt;
&lt;span id="train-on-past-quotes-and-generate-new-quotes"&gt;&lt;/span&gt;&lt;h2&gt;4. Train on past quotes and generate new quotes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GPT-3, The State of the Art Option&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Initially, I considered machine learning options for generating new text. The GPT-3 library, released in early 2020 by Open AI, is the current state of the art model for text generation. However, its API is only accessible on an invite basis. If I get access, I think I'll try using it with the &lt;a class="reference external" href="https://github.com/shreyashankar/gpt3-sandbox"&gt;GPT-Sandbox&lt;/a&gt; python library. ðŸ¤ž You can join the &lt;a class="reference external" href="https://share.hsforms.com/1Lfc7WtPLRk2ppXhPjcYY-A4sk30"&gt;GPT-3 waitlist here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I searched around for other text generation python libraries on Github and found a promising one named &lt;a class="reference external" href="https://github.com/minimaxir/gpt-2-simple"&gt;GPT-2_simple&lt;/a&gt;, which utilizes GPT-3's predecessor. However, it requires using an old version of TensorFlow. I feel less inclined to learn older versions of machine learning libraries. Currently, I'm holding out for GPT-3 access. I may try the GPT-2 route if I don't get a chance at GPT-3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A &amp;quot;&lt;/strong&gt;&lt;a class="reference external" href="https://zen-of-python.info/simple-is-better-than-complex.html"&gt;Simple is Better Than Complex&lt;/a&gt;&lt;strong&gt;&amp;quot; Approach: Markov Chain&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I wondered, are there any simpler options for text generation in python? Enter the Markov chain, which I stumbled across while Googling.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;Markov chain&lt;/strong&gt; is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.&lt;/p&gt;
&lt;p&gt;Wikipedia - &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain"&gt;https://en.wikipedia.org/wiki/Markov_chain&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Using the markovify library&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google pointed me to &lt;a class="reference external" href="https://analyticsindiamag.com/hands-on-guide-to-markov-chain-for-text-generation/"&gt;this post from Analytics India Magazine&lt;/a&gt; showing the &lt;a class="reference external" href="https://github.com/jsvine/markovify"&gt;&amp;quot;Markovify&amp;quot; library&lt;/a&gt;. Markovify makes generating your own Markov chain very easy! Install with pip:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;pip install markovify&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;Here's the code to create Markov chain on the quote text:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;span class="normal"&gt;1&lt;/span&gt;
&lt;span class="normal"&gt;2&lt;/span&gt;
&lt;span class="normal"&gt;3&lt;/span&gt;
&lt;span class="normal"&gt;4&lt;/span&gt;
&lt;span class="normal"&gt;5&lt;/span&gt;
&lt;span class="normal"&gt;6&lt;/span&gt;
&lt;span class="normal"&gt;7&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;markovify&lt;/span&gt;
&lt;span class="c1"&gt;# Build a markov chain model.&lt;/span&gt;
&lt;span class="n"&gt;text_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markovify&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Print five randomly-generated sentences&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_sentence&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;Markov chains are below the level of sophistication of machine learning technologies like GPT-3 or GPT-2. But Markov chains demonstrate how we can apply mathematics to mimic results or at least achieve an mvp with a simpler approach. Another intriguing tool worth mentioning is the &lt;a class="reference external" href="https://www.nltk.org/"&gt;nltk library&lt;/a&gt;, which offers natural language capabilities.&lt;/p&gt;
&lt;p&gt;Eventually I will try the more sophisticated way using machine learning, but at least I am enjoying a quick taste of success with a Markov chain. Here's what some cherry-picked results look like! ðŸ˜† Ok, they're not great, but not too shabby either for my first time generating text from examples:&lt;/p&gt;
&lt;div class="wp-image-4695 figure"&gt;
&lt;img alt="" src="https://pythonmarketer.files.wordpress.com/2020/10/generating_positive_thoughts.jpg?w=1024" /&gt;
&lt;/div&gt;
&lt;p&gt;Maybe in the future I will use this for posts on my Facebook page, but it's not quite ready yet! I really enjoyed the process of researching this challenge and hope this post helps you evaluate your own text generation possibilities. This was fun to learn about. And best of all, I achieved satisfying, albeit primitive results within one weekend. Thanks for reading and stay positive.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="check-out-markov-chain-in-the-wild-here"&gt;
&lt;span id="see-the-markov-chain-in-the-wild-at-positivipy-com"&gt;&lt;/span&gt;&lt;h2&gt;Check out Markov chain in the wild &lt;a class="reference external" href="https://positivethoughts.pythonanywhere.com/"&gt;here&lt;/a&gt;.&lt;/h2&gt;
&lt;/div&gt;
</content><category term="coding, data analysis, Google, pandas, programming, python"></category><category term="Google Vision"></category><category term="natural language"></category><category term="positive thinking"></category><category term="positivity"></category></entry></feed>